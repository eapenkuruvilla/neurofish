Small vs. Medium vs. Large
Network Size,Architecture,1st Layer Activation,Loss Func.,Error,WAC Test Result
small,256-128-64-1,tanh,mse,0.06,213/300,
large,1024-256-32-1,relu,mae,0.127,210/300
large,1024-256-32-1,relu,mse,0.045,216/300
medium,512-256-32-1,relu,mae,0.135,214/300
small,256-128-32-1,relu,mae,0146,208/300

Relu vs Tanh and MAE vs. MSE
Network Size,Architecture,1st Layer Activation,Loss Func.,Error,WAC
medium,512-256-32-1,relu,mae,0.136,234
medium,512-256-32-1,tanh,mae,0.143,235
medium,512-256-32-1,relu,mse,0.057,233

IS_BLAS_ENABLED, WAC,SF-2000, SF-2200
True: 233/300, 2246, 2300
False: v, 2223, 2265

2/5/26
WAC 263, ELO 2447

02/09/26
sudo apt update; sudo apt install build-essential libssl-dev libffi-dev zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libreadline-dev libgdbm-dev libsqlite3-dev libbz2-dev -y
pyenv install 3.14t
pyenv local 3.14t
Delete the old venv
python3.14t -m venv .venv
pip install --upgrade pip
pip install -r requirements.txt

02/10/26
2T=+80, WAC-257, nps:12233
After removing chess.Move - WAC:256
After eliminating python chess WAC=256

02/11/26
WAC:258, WAC-mp:254
WAC:262, WAC-mp:257
WAC:259, WAC-mp:258

02/12/26
ELO T2: 2435, T2:
WAC: 263, WAC-mp: 259
ELO T3: 2412
Progress 32/90: nf_3: +9-3=10 (64%) | nf_2: +4-7=11 (43%) | nf_1: +5-8=7 (42%)
WAC-mp: 261

python 13.3t
------------
(.venv) (base) eapen@OptiPlex-Ubuntu:~/Documents/Projects/neurofish$ THREADS=1 python lazy_smp.py
4r1k1/1bq2r1p/p2p1np1/3Pppb1/P1P5/1N3P2/1R2B1PP/1Q1R2BK w - - 0 1
info depth 5 score cp 59 nodes 42345 nps 12167 pv a4a5 g8f8 g1b6 c7b8 h1g1
nodes: 42345
nps: 12166
PV: a4a5 g8f8 g1b6 c7b8 h1g1

(.venv) (base) eapen@OptiPlex-Ubuntu:~/Documents/Projects/neurofish$ THREADS=3 python lazy_smp.py
info depth 5 score cp 57 nodes 81109 nps 29142 pv a4a5 g8f8 g1b6 c7b8 h1g1
nodes: 81109
nps: 29142
PV: a4a5 g8f8 g1b6 c7b8 h1g1

(.venv) (base) eapen@OptiPlex-Ubuntu:~/Documents/Projects/neurofish$ python test2.py
1 thread: 0.555s
2 threads: 1.183s (ideal: 0.555s)
Parallel efficiency: 46.9%

(.venv) (base) eapen@OptiPlex-Ubuntu:~/Documents/Projects/neurofish$ python test3.py
Testing with 20 iterations of fibonacci(35)...
Running in free-threaded build (GIL disabled). True parallelism possible.
Single-threaded time: 44.5648 seconds
Two-threaded time:    21.9173 seconds
Two threads were faster by 22.6475 seconds.

(.venv) (base) eapen@OptiPlex-Ubuntu:~/Documents/Projects/neurofish$ python test6.py
=== Separate dicts (no contention) ===
1 thread: 0.122s
2 threads: 0.106s
Efficiency: 114.6%
=== Shared dict (TT-like contention) ===
1 thread: 0.097s
2 threads: 0.233s

python 14.3t
------------
(.venv) (base) eapen@OptiPlex-Ubuntu:~/Documents/Projects/neurofish$ THREADS=1 python lazy_smp.py
info depth 5 score cp 59 nodes 42364 nps 15971 pv a4a5 g8f8 g1b6 c7b8 h1g1
nodes: 42364
nps: 15970
Best move: a4a5
PV: a4a5 g8f8 g1b6 c7b8 h1g1
(.venv) (base) eapen@OptiPlex-Ubuntu:~/Documents/Projects/neurofish$ THREADS=3 python lazy_smp.py
info depth 5 score cp 57 nodes 49079 nps 20802 pv a4a5 g8f8 g1b6 c7b8 h1g1
nodes: 49079
nps: 20802
Best move: a4a5
Score: 57
PV: a4a5 g8f8 g1b6 c7b8 h1g1

(.venv) (base) eapen@OptiPlex-Ubuntu:~/Documents/Projects/neurofish$ python test2.py
1 thread: 0.601s
2 threads: 1.500s (ideal: 0.601s)
Parallel efficiency: 40.1%

(.venv) (base) eapen@OptiPlex-Ubuntu:~/Documents/Projects/neurofish$ python test3.py
Testing with 20 iterations of fibonacci(35)...
Running in free-threaded build (GIL disabled). True parallelism possible.
Single-threaded time: 29.0114 seconds
Two-threaded time:    12.3457 seconds
Two threads were faster by 16.6657 seconds.

(.venv) (base) eapen@OptiPlex-Ubuntu:~/Documents/Projects/neurofish$ python test6.py
=== Separate dicts (no contention) ===
1 thread: 0.080s
2 threads: 0.098s
Efficiency: 81.5%
=== Shared dict (TT-like contention) ===
1 thread: 0.080s
2 threads: 0.202s
Efficiency: 39.4%

02/12/26
python 3.14t: WAC: 267, WAC-mp: 259
Sharded TT: WAC-265, WAC-mp-262

02/13/26
Adaptive QS depth: WAC-265, WAC-mp-262
No NN at shallow depths: WAC-261, WAC-mp-263, ELO-2430






